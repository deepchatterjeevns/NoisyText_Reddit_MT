{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of Copy of Trends_project-baseline_week3.ipynb","provenance":[{"file_id":"1BEq6oXGR_2ifrmaxALgkhyjUMRdZyTd7","timestamp":1587067704378},{"file_id":"1HZn7LEnlQ-hDGkGtUkSUuM1BrjFAFnhW","timestamp":1587067658371}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1587067696777,"user_tz":420,"elapsed":11830,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"id":"UKVirvNvguBt","outputId":"13898308-ba7d-4ae2-a8c9-69ccdfd0fa05","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HTCGgjd5huIo","colab":{}},"source":["import unicodedata\n","import string\n","import re\n","import random\n","\n","import time\n","import datetime\n","import math\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n","from gensim.models.wrappers import FastText\n","import spacy\n","import numpy as np\n","\n","#from redditscore.tokenizer import CrazyTokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hu_oS0yK33Su","colab_type":"code","outputId":"930b29c3-057f-4365-f2b0-d6dd27f7c101","executionInfo":{"status":"error","timestamp":1586914015442,"user_tz":420,"elapsed":262,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["\n","FASTTEXT_WORD2VEC = '/content/drive/My Drive/Colab Notebooks/cc.fr.300.bin'\n","french_model = FastText.load_fasttext_format(FASTTEXT_WORD2VEC)\n","weights_matrix = torch.zeros((len(SRC.vocab.itos), 300))\n","words_found = 0\n","\n","for i, word in enumerate(SRC.vocab.itos):\n","    try: \n","        word = word.lower()\n","        weights_matrix[i] = torch.FloatTensor(french_model[word])\n","        words_found += 1\n","    except KeyError:\n","        weights_matrix[i] = torch.rand((300,))\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-9b6f8bb9c550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFASTTEXT_WORD2VEC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'cc.fr.300.bin'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfrench_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_fasttext_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFASTTEXT_WORD2VEC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mweights_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwords_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data_folder' is not defined"]}]},{"cell_type":"code","metadata":{"id":"mVEiK92s5mXR","colab_type":"code","colab":{}},"source":["weights = torch.load(\"/content/drive/My Drive/Colab Notebooks/10320_fasttext_pt_word2vec.pt\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ca09jGTI7tNo","colab_type":"code","outputId":"5de267b7-1909-4933-df55-bd698dd9bf55","executionInfo":{"status":"ok","timestamp":1586939000323,"user_tz":420,"elapsed":984,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["weights.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10320, 300])"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586939009306,"user_tz":420,"elapsed":853,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"id":"KNlLSiPEhxYx","outputId":"8503fd39-440a-4809-acfc-8ec22bde5951","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["manual_seed = 77\n","torch.manual_seed(manual_seed)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","n_gpu = torch.cuda.device_count()\n","if n_gpu > 0:\n","    torch.cuda.manual_seed(manual_seed)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586926681051,"user_tz":420,"elapsed":16699,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"id":"v781ge9fiTDD","outputId":"a4f11842-583f-43ae-b2cf-35799893e667","colab":{"base_uri":"https://localhost:8080/","height":972}},"source":["!python -m spacy download en_core_web_sm\n","!python -m spacy download fr_core_news_sm"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","Collecting fr_core_news_sm==2.2.5\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n","\u001b[K     |████████████████████████████████| 14.7MB 408kB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.18.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (46.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.21.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.38.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.1.0)\n","Building wheels for collected packages: fr-core-news-sm\n","  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp36-none-any.whl size=14727027 sha256=c470c8dce22f9e86e8ce06c5baa6ae937f931fe2469e6ff6c71763f70b9d940b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-sog9rxy9/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n","Successfully built fr-core-news-sm\n","Installing collected packages: fr-core-news-sm\n","Successfully installed fr-core-news-sm-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('fr_core_news_sm')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mrUprtkUikXW","colab":{}},"source":["\n","import fr_core_news_sm\n","import en_core_web_sm\n","\n","spacy_fr = fr_core_news_sm.load()\n","spacy_en = en_core_web_sm.load()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sAgXHrZrjueN","colab":{}},"source":["import torchtext"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yU94BH23i8B8","colab":{}},"source":["def tokenize_fr(text):\n","    \"\"\"\n","    Tokenizes French text from a string into a list of strings (tokens)\n","    \"\"\"\n","    return [tok.text for tok in spacy_fr.tokenizer(text)]\n","\n","def tokenize_en(text):\n","    \"\"\"\n","    Tokenizes English text from a string into a list of strings (tokens)\n","    \"\"\"\n","    return [tok.text for tok in spacy_en.tokenizer(text)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-EqdDlbyyKd","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586927198900,"user_tz":420,"elapsed":12183,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"id":"5hsZWJAPi9TQ","outputId":"400c7f1e-df63-4758-83c6-cf04db0463d7","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["SRC = torchtext.data.Field(tokenize = tokenize_fr, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","TRG = torchtext.data.Field(tokenize = tokenize_en, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","train, val, test = torchtext.data.TabularDataset.splits(\n","    path='/content/drive/My Drive/Colab Notebooks/MTNT/train', train='output.tsv',validation='output_val.tsv', test='output_test.tsv', \n","    format='tsv', skip_header=True, fields=[('TRG', TRG), ('SRC', SRC)])\n","\n","print(f\"Number of training examples: {len(train.examples)}\")\n","print(f\"Number of validation examples: {len(val.examples)}\")\n","print(f\"Number of testing examples: {len(test.examples)}\")\n","\n","TRG.build_vocab(train, min_freq = 5)\n","SRC.build_vocab(train, min_freq = 5)\n","\n","print(f\"Unique tokens in source (fr) vocabulary: {len(SRC.vocab)}\")\n","print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")\n","\n","train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits(\n","    (train, val, test), # we pass in the datasets we want the iterator to draw data from\n","    batch_sizes=(16, 64, 64),device = device,\n","    sort_key=lambda x: len(x.SRC), # the BucketIterator needs to be told what function it should use to group the data.\n","    sort_within_batch=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of training examples: 18941\n","Number of validation examples: 875\n","Number of testing examples: 1021\n","Unique tokens in source (fr) vocabulary: 10320\n","Unique tokens in target (en) vocabulary: 8758\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aAJyXEft8jwF","colab_type":"code","colab":{}},"source":["\n","import pickle\n","with open(\"/content/drive/My Drive/Colab Notebooks/TRG.Field\",\"wb\")as f:\n","     pickle.dump(TRG,f)\n","\n","with open(\"/content/drive/My Drive/Colab Notebooks/SRC.Field\",\"wb\")as f:\n","     pickle.dump(SRC,f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1586926821640,"user_tz":420,"elapsed":617,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"id":"-qlVBJeYxw1m","outputId":"ac3028a0-0e95-447e-897a-0f8449a8b377","colab":{"base_uri":"https://localhost:8080/","height":164}},"source":["print(vars(train.examples)['SRC'])"],"execution_count":0,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-4a5db697e869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SRC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: vars() argument must have __dict__ attribute"]}]},{"cell_type":"code","metadata":{"id":"iqeJE7sDB4md","colab_type":"code","outputId":"c12e35e9-b87f-4cd3-cbdd-3a6a814aed1f","executionInfo":{"status":"ok","timestamp":1586927205142,"user_tz":420,"elapsed":910,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(vars(train.examples[-1])['SRC'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['une', 'perpignanaise', 'vit', '12', 'ans', 'sans', 'eau', 'courante', ',', 'la', 'saur', 'condamnée', ' ', 'ces', '200', '€', 'ça', 'doit', 'plus', 'ou', 'moins', 'être', 'une', 'consommation', 'annuelle', '(', 'à', 'la', 'louche', '100m3', ')', ',', \"c'\", 'est', 'de', \"l'\", 'eau', 'pas', 'de', \"l'\", 'essence', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bkceJiTes7sv","colab":{}},"source":["def train_attn(model, iterator, optimizer, criterion, clip):\n","    manual_seed = 77\n","    torch.manual_seed(manual_seed)\n","    if n_gpu > 0:\n","        torch.cuda.manual_seed(manual_seed)\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        src = batch.SRC\n","        trg = batch.TRG\n","        \n","        optimizer.zero_grad()\n","        \n","        output,_ = model(src, trg)\n","        \n","        #trg = [trg len, batch size]\n","        #output = [trg len, batch size, output dim]\n","        \n","        output_dim = output.shape[-1]\n","        \n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        \n","        #trg = [(trg len - 1) * batch size]\n","        #output = [(trg len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, trg)\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)\n","\n","def evaluate_attn(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            src = batch.SRC\n","            trg = batch.TRG\n","\n","            output,_ = model(src, trg, 0) #turn off teacher forcing\n","\n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            \n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)\n","\n","def init_weights(m):\n","    manual_seed = 77\n","    torch.manual_seed(manual_seed)\n","    if n_gpu > 0:\n","        torch.cuda.manual_seed(manual_seed)\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"izzNQZSlyjmv","colab":{}},"source":["def inference(model, file_name, src_vocab, trg_vocab, attention= False, max_trg_len = 64):\n","    '''\n","    Function for translation inference\n","\n","    Input: \n","    model: translation model;\n","    file_name: the directoy of test file that the first column is target reference, and the second column is source language;\n","    trg_vocab: Target torchtext Field\n","    attention: the model returns attention weights or not, default = False\n","    max_trg_len: the maximal length of translation text (optinal), default = 64\n","\n","    Output:\n","    Corpus BLEU score.\n","    '''\n","    from nltk.translate.bleu_score import corpus_bleu\n","    from nltk.translate.bleu_score import sentence_bleu\n","    from torchtext.data import TabularDataset\n","    from torchtext.data import Iterator\n","\n","    # convert index to text string\n","    def convert_itos(convert_vocab, token_ids):\n","        list_string = []\n","        for i in token_ids:\n","            if i == convert_vocab.vocab.stoi['<eos>']:\n","                break\n","            else:\n","                token = convert_vocab.vocab.itos[i]\n","                list_string.append(token)\n","        return list_string\n","\n","        \n","    test = TabularDataset(\n","      path=file_name, # the root directory where the data lies\n","      format='tsv',\n","      skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n","      fields=[('TRG', trg_vocab), ('SRC', src_vocab)])\n","\n","    test_iter = Iterator(\n","    dataset = test, # we pass in the datasets we want the iterator to draw data from\n","    sort = False,batch_size=128,\n","    sort_key=None,\n","    shuffle=False,\n","    sort_within_batch=False,\n","    device = device,\n","    train=False\n","    )\n","  \n","    model.eval()\n","    all_trg = []\n","    all_translated_trg = []\n","\n","    TRG_PAD_IDX = trg_vocab.vocab.stoi[trg_vocab.pad_token]\n","\n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(test_iter):\n","\n","            src = batch.SRC\n","            #src = [src len, batch size]\n","\n","            trg = batch.TRG\n","            #trg = [trg len, batch size]\n","\n","            batch_size = trg.shape[1]\n","\n","            # create a placeholder for traget language with shape of [max_trg_len, batch_size] where all the elements are the index of <pad>. Then send to device\n","            trg_placeholder = torch.Tensor(max_trg_len, batch_size)\n","            trg_placeholder.fill_(TRG_PAD_IDX)\n","            trg_placeholder = trg_placeholder.long().to(device)\n","            if attention == True:\n","                output,_ = model(src, trg_placeholder, 0) #turn off teacher forcing\n","            else:\n","                output = model(src, trg_placeholder, 0) #turn off teacher forcing\n","            # get translation results, we ignor first token <sos> in both translation and target sentences. \n","            # output_translate = [(trg len - 1), batch, output dim] output dim is size of target vocabulary.\n","            output_translate = output[1:]\n","            # store gold target sentences to a list \n","            all_trg.append(trg[1:].cpu())\n","\n","            # Choose top 1 word from decoder's output, we get the probability and index of the word\n","            prob, token_id = output_translate.data.topk(1)\n","            translation_token_id = token_id.squeeze(2).cpu()\n","\n","            # store gold target sentences to a list \n","            all_translated_trg.append(translation_token_id)\n","      \n","    all_gold_text = []\n","    all_translated_text = []\n","    for i in range(len(all_trg)): \n","        cur_gold = all_trg[i]\n","        cur_translation = all_translated_trg[i]\n","        for j in range(cur_gold.shape[1]):\n","            gold_convered_strings = convert_itos(trg_vocab,cur_gold[:,j])\n","            trans_convered_strings = convert_itos(trg_vocab,cur_translation[:,j])\n","\n","            all_gold_text.append(gold_convered_strings)\n","            all_translated_text.append(trans_convered_strings)\n","\n","    corpus_all_gold_text = [[item] for item in all_gold_text]\n","    corpus_bleu_score = corpus_bleu(corpus_all_gold_text, all_translated_text)  \n","    return corpus_bleu_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OyolUQ495eJK","colab_type":"code","outputId":"bef46881-881a-40c4-b5da-c2645000edf2","executionInfo":{"status":"ok","timestamp":1586939253963,"user_tz":420,"elapsed":964,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["weights.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10320, 300])"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"markdown","metadata":{"id":"cLQVdrbj5fEd","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j46M8hGqzcQh","colab":{}},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, n_layers, dropout):\n","        super().__init__()\n","\n","        self.emb_dim = emb_dim\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dropout = dropout\n","        self.n_layers = n_layers\n","\n","        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights))\n","        self.lstm = nn.LSTM(emb_dim, enc_hid_dim, n_layers, dropout=dropout, bidirectional = True)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src):\n","  \n","        embedded = self.dropout(self.embedding(src))\n","        \n","        outputs, (hidden, cell) = self.lstm(embedded)\n","       \n","        return outputs, (hidden, cell)\n","\n","\n","class Attention(nn.Module):\n","    def __init__(self, enc_hid_dim, dec_hid_dim):\n","        super().__init__()\n","        \n","        #self.W_a = nn.Linear(enc_hid_dim + dec_hid_dim, dec_hid_dim)\n","        #self.v_a = nn.Parameter(torch.rand(dec_hid_dim))\n","        \n","    def forward(self, hidden, encoder_outputs):\n","\n","        hidden = hidden[-1].unsqueeze(0).permute(1, 0, 2)\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 2, 0)\n","        attention_vector = torch.bmm(hidden, encoder_outputs).squeeze(1)\n","        \n","        return F.softmax(attention_vector, dim=1)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, dec_hid_dim, n_layers, dropout, attn):\n","        super().__init__()\n","\n","        self.emb_dim = emb_dim\n","        self.output_dim = output_dim\n","        self.dec_hid_dim = dec_hid_dim\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.lstm = nn.LSTM(emb_dim, dec_hid_dim, n_layers, dropout=dropout, bidirectional = False)\n","        self.fc_out = nn.Linear(dec_hid_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.f_mid = nn.Linear(dec_hid_dim * 2, dec_hid_dim)\n","        self.f_output = nn.Linear(dec_hid_dim, output_dim)\n","\n","        self.attn = attn\n","        \n","    def forward(self, input, hidden, cell, encoder_outputs):\n","             \n","        input = input.unsqueeze(0)\n","        embedded = self.dropout(self.embedding(input))\n","        \n","      \n","        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n","\n","        attention_weights = self.attn(hidden, encoder_outputs)\n","        attention_weights = attention_weights.unsqueeze(1)\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        weighted = torch.bmm(attention_weights, encoder_outputs)\n","        weighted = weighted.permute(1, 0, 2)\n","        concat = torch.cat((hidden[-1].unsqueeze(0), weighted), dim = 2)\n","        concat = concat.squeeze(0)\n","        s_prime = self.f_mid(concat)\n","        prediction = self.f_output(s_prime)\n","        \n","        return prediction, hidden, cell, attention_weights\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n","\n","        batch_size = src.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","\n","        all_attention_weights = torch.zeros(trg.shape[1], trg.shape[0]-1, src.shape[0])\n","\n","        encoder_outputs, (enc_hidden, enc_cell) = self.encoder(src)   #(4,8,512) (2, 8 ,1024)\n","        input = trg[0,:]\n","\n","        #print('Enc_hidden', enc_hidden.shape)\n","\n","        hidden1 = torch.cat((enc_hidden[0], enc_hidden[1]), dim = 1).unsqueeze(0)\n","        hidden2 = torch.cat((enc_hidden[2], enc_hidden[3]), dim = 1).unsqueeze(0)\n","        hidden = torch.cat((hidden1, hidden2), dim = 0)\n","        \n","        cell1 = torch.cat((enc_cell[0], enc_cell[1]), dim = 1).unsqueeze(0)\n","        cell2 = torch.cat((enc_cell[2], enc_cell[3]), dim = 1).unsqueeze(0)\n","        cell = torch.cat((cell1, cell2), dim = 0)\n","        for t in range(1, trg_len):\n","            \n","            output, hidden, cell, attention_weights = self.decoder(input, hidden, cell, encoder_outputs)\n","            \n","            all_attention_weights[:,t-1,:] = attention_weights.squeeze(1)\n","\n","            outputs[t] = output\n","\n","            teacher_force = random.random() < teacher_forcing_ratio\n","\n","            top1 = output.argmax(1) \n","\n","            input = trg[t] if teacher_force else top1\n","\n","        return outputs,all_attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586939083012,"user_tz":420,"elapsed":1093,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"id":"HoVmdBU_zk6K","outputId":"425238a1-bb80-45a7-ace0-c1e10dd63989","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["INPUT_DIM = 10320\n","OUTPUT_DIM = 8758\n","ENC_EMB_DIM = 300\n","DEC_EMB_DIM = 300\n","N_LAYERS = 2\n","BI_DIRECTION = True\n","ENC_HID_DIM = 512\n","DEC_HID_DIM = 512 * 2 # maybe times 2?\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.3\n","TEACH_FORCING_RATE = 0.5\n","LEARNING_RT = 0.001\n","MAX_EPOCH = 20\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n","\n","model = Seq2Seq(enc, dec, device).to(device)\n","\n","optimizer = optim.Adam(model.parameters(),lr=LEARNING_RT)\n","\n","def init_weights(m):\n","    manual_seed = 77\n","    torch.manual_seed(manual_seed)\n","    if n_gpu > 0:\n","        torch.cuda.manual_seed(manual_seed)\n","    for name, param in m.named_parameters():\n","        if 'encoder.embedding.weight' in name: \n","            continue \n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        \n","        else:\n","            nn.init.constant_(param.data, 0)\n","\n","model.apply(init_weights)\n","\n","TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","print('<pad> token index: ',TRG_PAD_IDX)\n","## we will ignore the pad token in true target set\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<pad> token index:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D1722RgTQ3RQ","colab_type":"code","outputId":"d50821aa-f969-44c6-ebe8-0b20eae10ceb","executionInfo":{"status":"ok","timestamp":1586939106489,"user_tz":420,"elapsed":898,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"colab":{"base_uri":"https://localhost:8080/","height":561}},"source":["for name, param in model.named_parameters():\n","  print(name,param.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["encoder.embedding.weight torch.Size([10320, 300])\n","encoder.lstm.weight_ih_l0 torch.Size([2048, 300])\n","encoder.lstm.weight_hh_l0 torch.Size([2048, 512])\n","encoder.lstm.bias_ih_l0 torch.Size([2048])\n","encoder.lstm.bias_hh_l0 torch.Size([2048])\n","encoder.lstm.weight_ih_l0_reverse torch.Size([2048, 300])\n","encoder.lstm.weight_hh_l0_reverse torch.Size([2048, 512])\n","encoder.lstm.bias_ih_l0_reverse torch.Size([2048])\n","encoder.lstm.bias_hh_l0_reverse torch.Size([2048])\n","encoder.lstm.weight_ih_l1 torch.Size([2048, 1024])\n","encoder.lstm.weight_hh_l1 torch.Size([2048, 512])\n","encoder.lstm.bias_ih_l1 torch.Size([2048])\n","encoder.lstm.bias_hh_l1 torch.Size([2048])\n","encoder.lstm.weight_ih_l1_reverse torch.Size([2048, 1024])\n","encoder.lstm.weight_hh_l1_reverse torch.Size([2048, 512])\n","encoder.lstm.bias_ih_l1_reverse torch.Size([2048])\n","encoder.lstm.bias_hh_l1_reverse torch.Size([2048])\n","decoder.embedding.weight torch.Size([8758, 300])\n","decoder.lstm.weight_ih_l0 torch.Size([4096, 300])\n","decoder.lstm.weight_hh_l0 torch.Size([4096, 1024])\n","decoder.lstm.bias_ih_l0 torch.Size([4096])\n","decoder.lstm.bias_hh_l0 torch.Size([4096])\n","decoder.lstm.weight_ih_l1 torch.Size([4096, 1024])\n","decoder.lstm.weight_hh_l1 torch.Size([4096, 1024])\n","decoder.lstm.bias_ih_l1 torch.Size([4096])\n","decoder.lstm.bias_hh_l1 torch.Size([4096])\n","decoder.fc_out.weight torch.Size([8758, 1024])\n","decoder.fc_out.bias torch.Size([8758])\n","decoder.f_mid.weight torch.Size([1024, 2048])\n","decoder.f_mid.bias torch.Size([1024])\n","decoder.f_output.weight torch.Size([8758, 1024])\n","decoder.f_output.bias torch.Size([8758])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586937701703,"user_tz":420,"elapsed":10470029,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"id":"Fget5kzuzuFV","outputId":"feeaea89-15ef-4861-ce29-221e4dd72aa2","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(MAX_EPOCH):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train_attn(model, train_iter, optimizer, criterion, CLIP)\n","    valid_loss = evaluate_attn(model, val_iter, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    # Create checkpoint at end of each epoch\n","    state_dict_model = model.state_dict() \n","    state = {\n","        'epoch': epoch,\n","        'state_dict': state_dict_model,\n","        'optimizer': optimizer.state_dict()\n","        }\n","\n","    torch.save(state, \"/content/drive/My Drive/Colab Notebooks/model_\"+str(epoch+1)+\".pt\")\n","\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Time: 8m 40s\n","\tTrain Loss: 5.717 | Train PPL: 303.942\n","\t Val. Loss: 5.932 |  Val. PPL: 376.820\n","Epoch: 02 | Time: 8m 45s\n","\tTrain Loss: 5.165 | Train PPL: 175.089\n","\t Val. Loss: 5.815 |  Val. PPL: 335.225\n","Epoch: 03 | Time: 8m 53s\n","\tTrain Loss: 4.817 | Train PPL: 123.645\n","\t Val. Loss: 5.648 |  Val. PPL: 283.644\n","Epoch: 04 | Time: 8m 39s\n","\tTrain Loss: 4.501 | Train PPL:  90.114\n","\t Val. Loss: 5.569 |  Val. PPL: 262.196\n","Epoch: 05 | Time: 8m 37s\n","\tTrain Loss: 4.233 | Train PPL:  68.957\n","\t Val. Loss: 5.613 |  Val. PPL: 274.027\n","Epoch: 06 | Time: 8m 35s\n","\tTrain Loss: 4.013 | Train PPL:  55.294\n","\t Val. Loss: 5.580 |  Val. PPL: 265.061\n","Epoch: 07 | Time: 8m 56s\n","\tTrain Loss: 3.814 | Train PPL:  45.322\n","\t Val. Loss: 5.471 |  Val. PPL: 237.697\n","Epoch: 08 | Time: 8m 55s\n","\tTrain Loss: 3.628 | Train PPL:  37.654\n","\t Val. Loss: 5.605 |  Val. PPL: 271.873\n","Epoch: 09 | Time: 8m 44s\n","\tTrain Loss: 3.445 | Train PPL:  31.355\n","\t Val. Loss: 5.723 |  Val. PPL: 305.773\n","Epoch: 10 | Time: 9m 2s\n","\tTrain Loss: 3.297 | Train PPL:  27.020\n","\t Val. Loss: 5.643 |  Val. PPL: 282.264\n","Epoch: 11 | Time: 8m 35s\n","\tTrain Loss: 3.142 | Train PPL:  23.147\n","\t Val. Loss: 5.686 |  Val. PPL: 294.591\n","Epoch: 12 | Time: 8m 25s\n","\tTrain Loss: 2.998 | Train PPL:  20.054\n","\t Val. Loss: 5.726 |  Val. PPL: 306.860\n","Epoch: 13 | Time: 8m 51s\n","\tTrain Loss: 2.847 | Train PPL:  17.242\n","\t Val. Loss: 5.900 |  Val. PPL: 364.944\n","Epoch: 14 | Time: 8m 51s\n","\tTrain Loss: 2.712 | Train PPL:  15.057\n","\t Val. Loss: 5.776 |  Val. PPL: 322.537\n","Epoch: 15 | Time: 8m 30s\n","\tTrain Loss: 2.590 | Train PPL:  13.325\n","\t Val. Loss: 6.068 |  Val. PPL: 431.736\n","Epoch: 16 | Time: 8m 50s\n","\tTrain Loss: 2.448 | Train PPL:  11.570\n","\t Val. Loss: 6.121 |  Val. PPL: 455.463\n","Epoch: 17 | Time: 8m 31s\n","\tTrain Loss: 2.340 | Train PPL:  10.384\n","\t Val. Loss: 6.184 |  Val. PPL: 484.973\n","Epoch: 18 | Time: 8m 47s\n","\tTrain Loss: 2.216 | Train PPL:   9.175\n","\t Val. Loss: 6.267 |  Val. PPL: 527.108\n","Epoch: 19 | Time: 8m 11s\n","\tTrain Loss: 2.115 | Train PPL:   8.288\n","\t Val. Loss: 6.424 |  Val. PPL: 616.531\n","Epoch: 20 | Time: 8m 27s\n","\tTrain Loss: 2.031 | Train PPL:   7.622\n","\t Val. Loss: 6.261 |  Val. PPL: 523.771\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586937755776,"user_tz":420,"elapsed":1557,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"id":"lL5kbzf43tHg","outputId":"8d135cc0-5782-4e19-801b-a420d00e35ec","colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["path = \"/content/drive/My Drive/Colab Notebooks/MTNT/train/output.tsv\"\n","\n","tests = []\n","with open(path) as f:\n","  f = f.readlines()\n","  for i in range(3):\n","    print(f[765 + i].split(\"\\t\")[1])\n","    tests.append(f[765 + i].split(\"\\t\")[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A partir de ce moment la, j'arrive plus a contenir mes sentiments mais je sais que la distance fait que rien ne se passera et j'essaye de passer outre, mais j'y arrive pas.\n","\n","A partir de la, c'est la descente aux enfers.\n","\n","A partir de là il est facile de choisir les arguments les plus idiots et de les contredire.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d9IPqs8o3SJw","colab_type":"code","colab":{}},"source":["INPUT_DIM = 10320\n","OUTPUT_DIM = 8758\n","ENC_EMB_DIM = 300\n","DEC_EMB_DIM = 300\n","N_LAYERS = 2\n","BI_DIRECTION = True\n","ENC_HID_DIM = 512\n","DEC_HID_DIM = 512 * 2 # maybe times 2?\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.3\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n","\n","model_best = Seq2Seq(enc, dec, device).to(device)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1ei3YMU5QwG","colab_type":"code","outputId":"a2594c08-dbf7-4da8-f38e-7e2fe9b15568","executionInfo":{"status":"ok","timestamp":1586939282472,"user_tz":420,"elapsed":898,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["model_best"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(10320, 300)\n","    (lstm): LSTM(300, 512, num_layers=2, dropout=0.5, bidirectional=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(8758, 300)\n","    (lstm): LSTM(300, 1024, num_layers=2, dropout=0.3)\n","    (fc_out): Linear(in_features=1024, out_features=8758, bias=True)\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (f_mid): Linear(in_features=2048, out_features=1024, bias=True)\n","    (f_output): Linear(in_features=1024, out_features=8758, bias=True)\n","    (attn): Attention()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"xc5XqsnM3y6Q","colab_type":"code","outputId":"96dd6f89-d574-46a8-c123-59901ecec5e7","executionInfo":{"status":"ok","timestamp":1586939558507,"user_tz":420,"elapsed":4113,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model_best.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/model_6.pt')['state_dict'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"code","metadata":{"id":"L8iXUHgK9SQF","colab_type":"code","colab":{}},"source":["tests = [['<sos>', 'a', 'partir', 'de', 'ce', 'moment', 'la', ',', \"j'\", 'arrive', 'plus', 'a', 'contenir', 'mes', 'sentiments', 'mais', 'je', 'sais', 'que', 'la', 'distance', 'fait', 'que', 'rien', 'ne', 'se', 'passera', 'et', \"j'\", 'essaye', 'de', 'passer', 'outre', ',', 'mais', \"j'\", 'y', 'arrive', 'pas', '.']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1586939558509,"user_tz":420,"elapsed":3098,"user":{"displayName":"罗伊Roy","photoUrl":"","userId":"08401560910075141711"}},"id":"osvpRl2G0r3-","outputId":"fc553a87-bdc5-4001-a7f5-9b0ac57b55b7","colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["# sents = [sentence_1, sentence_2, sentence_3]\n","\n","ind = 1\n","for sent in tests:\n","\n","  model_best.eval()\n","  src_token = SRC.preprocess(sent)\n","  print(\"src_token:\", src_token)\n","  src_tensor = SRC.process([src_token],device=device)\n","  print(\"shape of source language: \", src_tensor.shape)\n","\n","  trg_token = ['<pad>']*64\n","  trg_tensor = TRG.process([trg_token],device=device)\n","\n","  output, all_attention_weights = model(src_tensor, trg_tensor,teacher_forcing_ratio = 0.0)\n","  output_dim = output.shape[-1] \n","  output_translate = output[1:]\n","\n","  source_language = src_tensor[:,0].cpu().numpy()\n","  translation_logit = output_translate[:,0,:].squeeze(1)\n","  weights = all_attention_weights[0,:,:].squeeze(1).cpu().detach().numpy()\n","\n","  prob, token_id = translation_logit.data.topk(1)\n","  token_id = token_id.squeeze(1).cpu().numpy()\n","\n","  src_language = []\n","\n","  for i in source_language:\n","      if i == SRC.vocab.stoi['<eos>']:\n","          break\n","      else:\n","          token = SRC.vocab.itos[i]\n","          src_language.append(token)\n","  print(\"Source language:\", src_language)\n","\n","  trans_language = []\n","\n","  for i in token_id:\n","      if i == TRG.vocab.stoi['<eos>']:\n","          break\n","      else:\n","          token = TRG.vocab.itos[i]\n","          trans_language.append(token)\n","  print(\"Our model translation: \", trans_language)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["src_token: ['<sos>', 'a', 'partir', 'de', 'ce', 'moment', 'la', ',', \"j'\", 'arrive', 'plus', 'a', 'contenir', 'mes', 'sentiments', 'mais', 'je', 'sais', 'que', 'la', 'distance', 'fait', 'que', 'rien', 'ne', 'se', 'passera', 'et', \"j'\", 'essaye', 'de', 'passer', 'outre', ',', 'mais', \"j'\", 'y', 'arrive', 'pas', '.']\n","shape of source language:  torch.Size([42, 1])\n","Source language: ['<sos>', '<sos>', 'a', 'partir', 'de', 'ce', 'moment', 'la', ',', \"j'\", 'arrive', 'plus', 'a', 'contenir', 'mes', 'sentiments', 'mais', 'je', 'sais', 'que', 'la', 'distance', 'fait', 'que', 'rien', 'ne', 'se', 'passera', 'et', \"j'\", 'essaye', 'de', 'passer', 'outre', ',', 'mais', \"j'\", 'y', 'arrive', 'pas', '.']\n","Our model translation:  ['adults', 'bercy', 'conventional', 'condo', 'condo', 'sprays', 'sprays', 'modify', 'leaves', 'basic', 'course', 'leaves', '\\t', 'vomit', 'trying', 'supermarkets', 'poll', 'actress', 'linking', 'christian', 'incompetence', 'desks', 'develop', 'frames', 'frames', 'bonus', 'bonus', 'travel', 'caledonia', 'sniffed', 'competing', 'joute', 'joute', 'suggest', 'win', 'taboo', 'centimeters', 'throat', 'word2vec', 'onions', 'leopard', 'factors', 'wire', 'temples', 'deported', 'satellite', 'satellite', 'chinese', 'beginning', 'ashamed', 'attack', 'abilities', 'composter', 'trade', 'drove', 'proletarian', 'protection', 'magnitude', 'relatively', 'crying', 'mortgage', 'permit', 'governed', 'governed', 'questions']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xbfdv08b4OJ0","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}