{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "20_BLEU_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UKVirvNvguBt",
        "outputId": "abc05e96-e285-436f-ae3b-da7e915bde00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HTCGgjd5huIo",
        "colab": {}
      },
      "source": [
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "# from redditscore.tokenizer import CrazyTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9COjhVu1OY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! pip install transformers\n",
        "# import os\n",
        "# assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KNlLSiPEhxYx",
        "outputId": "e70184a2-2220-4694-bb3e-294f1726c6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "manual_seed = 77\n",
        "torch.manual_seed(manual_seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "n_gpu = torch.cuda.device_count()\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed(manual_seed)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "skB8ddU3iCZd",
        "outputId": "570cb758-4d40-49e2-b1a0-26e0138fa213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2t7cMZM24Zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "\n",
        "# device = xm.xla_device()\n",
        "# print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v781ge9fiTDD",
        "colab": {}
      },
      "source": [
        "# !python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download fr_core_news_sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mrUprtkUikXW",
        "outputId": "c14a9ff6-8c2d-4a0a-eb2f-93b494a4305b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        }
      },
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm\n",
        "\n",
        "import fr_core_news_sm\n",
        "import en_core_web_sm\n",
        "\n",
        "spacy_fr = fr_core_news_sm.load()\n",
        "spacy_en = en_core_web_sm.load()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Collecting fr_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp36-none-any.whl size=14727027 sha256=6050d4465f8a4a7bf60d5dce927247d354e47dfef1872cb6f0bd9b96fcbd6824\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bw4a5fvi/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sAgXHrZrjueN",
        "colab": {}
      },
      "source": [
        "import torchtext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yU94BH23i8B8",
        "colab": {}
      },
      "source": [
        "def tokenize_fr(text):\n",
        "    \"\"\"\n",
        "    Tokenizes French text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-EqdDlbyyKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2FDFe6kAf58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/data/MTNT/valid/valid.fr-en.tsv\") as data:\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/data/MTNT/train/output_val.tsv', 'wt') as out_file:\n",
        "    rd = csv.reader(data, delimiter=\"\\t\", quotechar='\"')\n",
        "    for l in rd:\n",
        "      if len(l) < 3:\n",
        "        print(l)\n",
        "        continue\n",
        "      tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "      tsv_writer.writerow([l[2], l[1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCQUNSVbAphq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/MTNT/test/test.fr-en.tsv\") as data:\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/MTNT/train/output_test.tsv', 'wt') as out_file:\n",
        "    rd = csv.reader(data, delimiter=\"\\t\", quotechar='\"')\n",
        "    for l in rd:\n",
        "      if len(l) < 3:\n",
        "        print(l)\n",
        "        continue\n",
        "      tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "      tsv_writer.writerow([l[2], l[1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3X_3BYO3km8",
        "colab_type": "code",
        "outputId": "545b2bf5-94fb-4135-d404-4bd95e139c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/MTNT/train/train.fr-en.tsv\") as data:\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/MTNT/train/output.tsv', 'wt') as out_file:\n",
        "    rd = csv.reader(data, delimiter=\"\\t\", quotechar='\"')\n",
        "    for l in rd:\n",
        "      if len(l) < 3:\n",
        "        print(l)\n",
        "        continue\n",
        "      tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "      tsv_writer.writerow([l[2], l[1]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['4312', '*\\t*']\n",
            "['5167', '2008 !\\t2008!']\n",
            "['6545', ':D\\t:D\\n3823\\tDe 2000 à 2012 tu veux dire.\\tFrom 2000 to 2012 you mean.\\n4141\\tDear French Redditors, could you help me to find this song?\\tDear French Redditors, could you help me to find this song?\\n6637\\t* Death roes of the Republic -> Sur la chute de la république romaine.\\t* Death roes of the Republic -> About the fall of the Romanian republic.\\n9529\\t* Death roes of the Republic -> Sur la chute de la république romaine.\\t* Death roes of the Republic -> On the fall of the Roman republic.\\n9807\\tDébat : « Balance ton transport », ou quand la RATP diabolise les animaux pour lutter contre le harcèlement sexuel  En quoi mettre un homme harceleur serait caricaturale ou problématique ?   Illustrer des comportements nocifs par des représentations réalistes est quelque chose de normal (voir sécurité routière par exemple).\\tDebate: Throw our your transportation,\" or when the RATP demonizes animals to fight against sexual harassment. How is a man who harasses a caricature or problematic? Illustrating harmful behaviors with realistic representations is something that is normal (see traffic safety, for instance).']\n",
            "['9710', ', dispo sur Spotify.\\tI discovered a pretty good philosophy podcast: Philosophize This!,\" which is available on Spotify.']\n",
            "['7698', '* etc etc.\\tor \\'\\'NO we didn\\'t make 50 holes in your wall!!\\'\\'\\n5574\\tEt cette prestance, ce maintien.\\tAnd this presence is constant.\\n8896\\tEt Cheminade.\\tAnd Solidarity and Progress.\\n9257\\tEt chez lui y a des tapis.\\tAnd there are carpets at his place.\\n3141\\tetc.\\tI started comparing everyday life situations with what I had here in Germany and unfortunately, the region where I come from couldn\\'t tip the scales in its favor (ecology, social problems, noise, pollution, rain, rushes, long commutes to work, etc., etc., etc.).\\n7690\\tEt combien tués en en Europe par des Africains ?\\tAnd how many were killed in Europe by Africans?\\n7862\\tEt comme dirait James Franco, ils nous saquent parce qu\\'on les nique!\\tAnd as James Franco would say, they downvote us because we fuck them!\\n658\\tEt comme dirait James Franco, ils nous saquent parce qu\\'on les nique!\\tAnd as James Franco would say: They hate us because they ain\\'t us\"!']\n",
            "['2365', 'J’ai vu cette vidéo qui est un pur montage.\\tI saw this video which is a pure montage.']\n",
            "['4667', \", mais pour travailler à temps plein avec du publique, je peux vous dire que ça manque pas mal à certains.\\t, but I work with the public full-time and I can assure you that some people don't even have that much.\"]\n",
            "['8762', 'Ne pas se poser de questions et tirer !\\tDon\\'t ask questions and shoot!,\" was the shocking reply from Perrine Goulet, a LaRem deputy and former employee of a nuclear plant and member of the board of administration of IRSN France.']\n",
            "['2852', \"Oh j'ai trouvé un Magnum!\\tOh I've found a Magnum!\"]\n",
            "['5188', 'Ouhouh police !\\tUh huh police!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5hsZWJAPi9TQ",
        "outputId": "1a1cd46f-405b-4ab8-b67c-e99b1f7ddd49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "SRC = torchtext.data.Field(tokenize = tokenize_fr, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "TRG = torchtext.data.Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "\n",
        "train, val, test = torchtext.data.TabularDataset.splits(\n",
        "    path='/content/drive/My Drive/Colab Notebooks/Trends Project/data/', train='output.tsv',validation='output_val.tsv', test='output_test.tsv', \n",
        "    format='tsv', skip_header=True, fields=[('TRG', TRG), ('SRC', SRC)])\n",
        "\n",
        "print(f\"Number of training examples: {len(train.examples)}\")\n",
        "print(f\"Number of validation examples: {len(val.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test.examples)}\")\n",
        "\n",
        "TRG.build_vocab(train, max_size = 6000)\n",
        "SRC.build_vocab(train, max_size = 6000)\n",
        "# TRG.build_vocab(train, min_freq = 5)\n",
        "# SRC.build_vocab(train, min_freq = 5)\n",
        "\n",
        "print(f\"Unique tokens in source (fr) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")\n",
        "\n",
        "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
        "    (train, val, test), # we pass in the datasets we want the iterator to draw data from\n",
        "    batch_sizes=(4, 64, 64),device = device,\n",
        "    sort_key=lambda x: len(x.SRC), # the BucketIterator needs to be told what function it should use to group the data.\n",
        "    sort_within_batch=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 18941\n",
            "Number of validation examples: 875\n",
            "Number of testing examples: 1021\n",
            "Unique tokens in source (fr) vocabulary: 6004\n",
            "Unique tokens in target (en) vocabulary: 6004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-qlVBJeYxw1m",
        "outputId": "d091ed0d-62c6-4b67-b3e6-79d943a88318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(vars(train.examples[-1])['TRG'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['perpignan', 'woman', 'lives', 'for', '12', 'years', 'without', 'running', 'water', '.', 'saur', 'sentences', '.', 'these', '€', '200', 'should', 'be', 'more', 'or', 'less', 'the', 'annual', 'consumption', '(', 'for', '100m3', ')', '.', 'it', \"'s\", 'water', ',', 'not', 'gasoline', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqeJE7sDB4md",
        "colab_type": "code",
        "outputId": "ccc72b3f-c64a-497d-b1af-947f2487da52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(vars(train.examples[-1])['SRC'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['une', 'perpignanaise', 'vit', '12', 'ans', 'sans', 'eau', 'courante', ',', 'la', 'saur', 'condamnée', ' ', 'ces', '200', '€', 'ça', 'doit', 'plus', 'ou', 'moins', 'être', 'une', 'consommation', 'annuelle', '(', 'à', 'la', 'louche', '100m3', ')', ',', \"c'\", 'est', 'de', \"l'\", 'eau', 'pas', 'de', \"l'\", 'essence', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bkceJiTes7sv",
        "colab": {}
      },
      "source": [
        "def train_attn(model, iterator, optimizer, criterion, clip):\n",
        "    manual_seed = 77\n",
        "    torch.manual_seed(manual_seed)\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed(manual_seed)\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.SRC\n",
        "        trg = batch.TRG\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output,_ = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate_attn(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.SRC\n",
        "            trg = batch.TRG\n",
        "\n",
        "            output,_ = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def init_weights(m):\n",
        "    manual_seed = 77\n",
        "    torch.manual_seed(manual_seed)\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed(manual_seed)\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "izzNQZSlyjmv",
        "colab": {}
      },
      "source": [
        "def inference(model, file_name, src_vocab, trg_vocab, attention= False, max_trg_len = 64):\n",
        "    '''\n",
        "    Function for translation inference\n",
        "\n",
        "    Input: \n",
        "    model: translation model;\n",
        "    file_name: the directoy of test file that the first column is target reference, and the second column is source language;\n",
        "    trg_vocab: Target torchtext Field\n",
        "    attention: the model returns attention weights or not, default = False\n",
        "    max_trg_len: the maximal length of translation text (optinal), default = 64\n",
        "\n",
        "    Output:\n",
        "    Corpus BLEU score.\n",
        "    '''\n",
        "    from nltk.translate.bleu_score import corpus_bleu\n",
        "    from nltk.translate.bleu_score import sentence_bleu\n",
        "    from torchtext.data import TabularDataset\n",
        "    from torchtext.data import Iterator\n",
        "\n",
        "    # convert index to text string\n",
        "    def convert_itos(convert_vocab, token_ids):\n",
        "        list_string = []\n",
        "        for i in token_ids:\n",
        "            if i == convert_vocab.vocab.stoi['<eos>']:\n",
        "                break\n",
        "            else:\n",
        "                token = convert_vocab.vocab.itos[i]\n",
        "                list_string.append(token)\n",
        "        return list_string\n",
        "\n",
        "        \n",
        "    test = TabularDataset(\n",
        "      path=file_name, # the root directory where the data lies\n",
        "      format='tsv',\n",
        "      skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "      fields=[('TRG', trg_vocab), ('SRC', src_vocab)])\n",
        "\n",
        "    test_iter = Iterator(\n",
        "    dataset = test, # we pass in the datasets we want the iterator to draw data from\n",
        "    sort = False,batch_size=128,\n",
        "    sort_key=None,\n",
        "    shuffle=False,\n",
        "    sort_within_batch=False,\n",
        "    device = device,\n",
        "    train=False\n",
        "    )\n",
        "  \n",
        "    model.eval()\n",
        "    all_trg = []\n",
        "    all_translated_trg = []\n",
        "\n",
        "    TRG_PAD_IDX = trg_vocab.vocab.stoi[trg_vocab.pad_token]\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(test_iter):\n",
        "\n",
        "            src = batch.SRC\n",
        "            #src = [src len, batch size]\n",
        "\n",
        "            trg = batch.TRG\n",
        "            #trg = [trg len, batch size]\n",
        "\n",
        "            batch_size = trg.shape[1]\n",
        "\n",
        "            # create a placeholder for traget language with shape of [max_trg_len, batch_size] where all the elements are the index of <pad>. Then send to device\n",
        "            trg_placeholder = torch.Tensor(max_trg_len, batch_size)\n",
        "            trg_placeholder.fill_(TRG_PAD_IDX)\n",
        "            trg_placeholder = trg_placeholder.long().to(device)\n",
        "            if attention == True:\n",
        "                output,_ = model(src, trg_placeholder, 0) #turn off teacher forcing\n",
        "            else:\n",
        "                output = model(src, trg_placeholder, 0) #turn off teacher forcing\n",
        "            # get translation results, we ignor first token <sos> in both translation and target sentences. \n",
        "            # output_translate = [(trg len - 1), batch, output dim] output dim is size of target vocabulary.\n",
        "            output_translate = output[1:]\n",
        "            # store gold target sentences to a list \n",
        "            all_trg.append(trg[1:].cpu())\n",
        "\n",
        "            # Choose top 1 word from decoder's output, we get the probability and index of the word\n",
        "            prob, token_id = output_translate.data.topk(1)\n",
        "            translation_token_id = token_id.squeeze(2).cpu()\n",
        "\n",
        "            # store gold target sentences to a list \n",
        "            all_translated_trg.append(translation_token_id)\n",
        "      \n",
        "    all_gold_text = []\n",
        "    all_translated_text = []\n",
        "    for i in range(len(all_trg)): \n",
        "        cur_gold = all_trg[i]\n",
        "        cur_translation = all_translated_trg[i]\n",
        "        for j in range(cur_gold.shape[1]):\n",
        "            gold_convered_strings = convert_itos(trg_vocab,cur_gold[:,j])\n",
        "            trans_convered_strings = convert_itos(trg_vocab,cur_translation[:,j])\n",
        "\n",
        "            all_gold_text.append(gold_convered_strings)\n",
        "            all_translated_text.append(trans_convered_strings)\n",
        "\n",
        "    corpus_all_gold_text = [[item] for item in all_gold_text]\n",
        "    corpus_bleu_score = corpus_bleu(corpus_all_gold_text, all_translated_text)  \n",
        "    return corpus_bleu_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j46M8hGqzcQh",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dropout = dropout\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, enc_hid_dim, n_layers, dropout=dropout, bidirectional = True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "  \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        \n",
        "        return outputs, (hidden, cell)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        #self.W_a = nn.Linear(enc_hid_dim + dec_hid_dim, dec_hid_dim)\n",
        "        #self.v_a = nn.Parameter(torch.rand(dec_hid_dim))\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "\n",
        "        hidden = hidden.permute(1, 0, 2)\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 2, 0)\n",
        "        attention_vector = torch.bmm(hidden, encoder_outputs).squeeze(1)\n",
        "        \n",
        "        return F.softmax(attention_vector, dim=1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, dec_hid_dim, n_layers, dropout, attn):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, dec_hid_dim, n_layers, dropout=dropout, bidirectional = False)\n",
        "        self.fc_out = nn.Linear(dec_hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.f_mid = nn.Linear(dec_hid_dim * 2, dec_hid_dim)\n",
        "        self.f_output = nn.Linear(dec_hid_dim, output_dim)\n",
        "\n",
        "        self.attn = attn\n",
        "        \n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "             \n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        attention_weights = self.attn(hidden, encoder_outputs)\n",
        "        attention_weights = attention_weights.unsqueeze(1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted = torch.bmm(attention_weights, encoder_outputs)\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        concat = torch.cat((hidden, weighted), dim = 2)\n",
        "        concat = concat.squeeze(0)\n",
        "        s_prime = self.f_mid(concat)\n",
        "        prediction = self.f_output(s_prime)\n",
        "        \n",
        "        return prediction, hidden, cell, attention_weights\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        all_attention_weights = torch.zeros(trg.shape[1], trg.shape[0]-1, src.shape[0])\n",
        "\n",
        "        encoder_outputs, (enc_hidden, enc_cell) = self.encoder(src)\n",
        "\n",
        "        input = trg[0,:]\n",
        "\n",
        "        #print('Enc_hidden', enc_hidden.shape)\n",
        "\n",
        "        hidden = torch.cat((enc_hidden[0], enc_hidden[1]), dim = 1).unsqueeze(0)\n",
        "        cell = torch.cat((enc_cell[0], enc_cell[1]), dim = 1).unsqueeze(0)\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            output, hidden, cell, attention_weights = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "            \n",
        "            all_attention_weights[:,t-1,:] = attention_weights.squeeze(1)\n",
        "\n",
        "            outputs[t] = output\n",
        "\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            top1 = output.argmax(1) \n",
        "\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs,all_attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HoVmdBU_zk6K",
        "outputId": "2ce01a38-7398-4d82-aca6-577cb5e16578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "INPUT_DIM = 6004\n",
        "OUTPUT_DIM = 6004\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "N_LAYERS = 1\n",
        "BI_DIRECTION = True\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512 * 2 # maybe times 2?\n",
        "ENC_DROPOUT = 0.3\n",
        "DEC_DROPOUT = 0.3\n",
        "TEACH_FORCING_RATE = 0.5\n",
        "LEARNING_RT = 0.001\n",
        "MAX_EPOCH = 15\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=LEARNING_RT)\n",
        "\n",
        "def init_weights(m):\n",
        "    manual_seed = 77\n",
        "    torch.manual_seed(manual_seed)\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed(manual_seed)\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "print('<pad> token index: ',TRG_PAD_IDX)\n",
        "## we will ignore the pad token in true target set\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<pad> token index:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fget5kzuzuFV",
        "colab": {}
      },
      "source": [
        "# CLIP = 1\n",
        "\n",
        "# best_valid_loss = float('inf')\n",
        "\n",
        "# for epoch in range(MAX_EPOCH):\n",
        "    \n",
        "#     start_time = time.time()\n",
        "    \n",
        "#     train_loss = train_attn(model, train_iter, optimizer, criterion, CLIP)\n",
        "#     valid_loss = evaluate_attn(model, val_iter, criterion)\n",
        "    \n",
        "#     end_time = time.time()\n",
        "    \n",
        "#     epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "#     # Create checkpoint at end of each epoch\n",
        "#     state_dict_model = model.state_dict() \n",
        "#     state = {\n",
        "#         'epoch': epoch,\n",
        "#         'state_dict': state_dict_model,\n",
        "#         'optimizer': optimizer.state_dict()\n",
        "#         }\n",
        "\n",
        "#     # torch.save(state, \"./drive/My Drive/Colab Notebooks/ckpt_lab3_attn/seq2seq_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "#     print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "#     print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yizcgMt0cNZ4",
        "colab_type": "code",
        "outputId": "2a4ee278-a4e2-4b35-dc5c-ab49b412ed1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(MAX_EPOCH):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train_attn(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate_attn(model, val_iter, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    # Create checkpoint at end of each epoch\n",
        "    state_dict_model = model.state_dict() \n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': state_dict_model,\n",
        "        'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "    torch.save(state, \"/content/drive/My Drive/Colab Notebooks/Trends Project/epoch_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 22m 22s\n",
            "\tTrain Loss: 4.985 | Train PPL: 146.260\n",
            "\t Val. Loss: 5.225 |  Val. PPL: 185.822\n",
            "Epoch: 02 | Time: 22m 26s\n",
            "\tTrain Loss: 3.815 | Train PPL:  45.399\n",
            "\t Val. Loss: 4.934 |  Val. PPL: 138.929\n",
            "Epoch: 03 | Time: 22m 21s\n",
            "\tTrain Loss: 3.253 | Train PPL:  25.858\n",
            "\t Val. Loss: 4.894 |  Val. PPL: 133.474\n",
            "Epoch: 04 | Time: 22m 17s\n",
            "\tTrain Loss: 2.930 | Train PPL:  18.719\n",
            "\t Val. Loss: 4.727 |  Val. PPL: 112.974\n",
            "Epoch: 05 | Time: 22m 37s\n",
            "\tTrain Loss: 2.686 | Train PPL:  14.669\n",
            "\t Val. Loss: 4.746 |  Val. PPL: 115.090\n",
            "Epoch: 06 | Time: 22m 18s\n",
            "\tTrain Loss: 2.495 | Train PPL:  12.116\n",
            "\t Val. Loss: 4.783 |  Val. PPL: 119.496\n",
            "Epoch: 07 | Time: 22m 7s\n",
            "\tTrain Loss: 2.325 | Train PPL:  10.225\n",
            "\t Val. Loss: 4.924 |  Val. PPL: 137.501\n",
            "Epoch: 08 | Time: 22m 23s\n",
            "\tTrain Loss: 2.184 | Train PPL:   8.878\n",
            "\t Val. Loss: 4.911 |  Val. PPL: 135.802\n",
            "Epoch: 09 | Time: 22m 40s\n",
            "\tTrain Loss: 2.050 | Train PPL:   7.769\n",
            "\t Val. Loss: 5.059 |  Val. PPL: 157.468\n",
            "Epoch: 10 | Time: 22m 39s\n",
            "\tTrain Loss: 1.947 | Train PPL:   7.008\n",
            "\t Val. Loss: 5.088 |  Val. PPL: 162.023\n",
            "Epoch: 11 | Time: 22m 20s\n",
            "\tTrain Loss: 1.857 | Train PPL:   6.402\n",
            "\t Val. Loss: 5.119 |  Val. PPL: 167.126\n",
            "Epoch: 12 | Time: 22m 31s\n",
            "\tTrain Loss: 1.777 | Train PPL:   5.912\n",
            "\t Val. Loss: 5.285 |  Val. PPL: 197.288\n",
            "Epoch: 13 | Time: 22m 17s\n",
            "\tTrain Loss: 1.705 | Train PPL:   5.503\n",
            "\t Val. Loss: 5.417 |  Val. PPL: 225.133\n",
            "Epoch: 14 | Time: 22m 12s\n",
            "\tTrain Loss: 1.648 | Train PPL:   5.195\n",
            "\t Val. Loss: 5.260 |  Val. PPL: 192.528\n",
            "Epoch: 15 | Time: 21m 51s\n",
            "\tTrain Loss: 1.586 | Train PPL:   4.885\n",
            "\t Val. Loss: 5.325 |  Val. PPL: 205.327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yayiu4BiJ5RI",
        "colab_type": "code",
        "outputId": "562fea46-49b6-41e3-c91f-a4d391f094dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n",
        "\n",
        "model_best = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=LEARNING_RT)\n",
        "\n",
        "model_best.apply(init_weights)\n",
        "\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "print('<pad> token index: ',TRG_PAD_IDX)\n",
        "## we will ignore the pad token in true target set\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "model_best.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/Trends Project/epoch_4.pt\")['state_dict'])\n",
        "\n",
        "print(inference(model_best, \"/content/drive/My Drive/Colab Notebooks/Trends Project/data/output_test.tsv\", SRC, TRG, True, 64))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<pad> token index:  1\n",
            "0.19694590142119364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P9OTZL8y7gL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "52c4ab1e-52cf-43a5-b746-7029a32befaa"
      },
      "source": [
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n",
        "\n",
        "model_best = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=LEARNING_RT)\n",
        "\n",
        "model_best.apply(init_weights)\n",
        "\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "print('<pad> token index: ',TRG_PAD_IDX)\n",
        "## we will ignore the pad token in true target set\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "model_best.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/Trends Project/epoch_15.pt\")['state_dict'])\n",
        "\n",
        "print(inference(model_best, \"/content/drive/My Drive/Colab Notebooks/Trends Project/data/output_test.tsv\", SRC, TRG, True, 64))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<pad> token index:  1\n",
            "0.2026407182435025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lL5kbzf43tHg",
        "outputId": "7f7b8cae-89c9-432e-aacc-fd0ad2fd010b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "path = \"/content/drive/My Drive/Colab Notebooks/Trends Project/data/output.tsv\"\n",
        "\n",
        "tests = []\n",
        "with open(path) as f:\n",
        "  f = f.readlines()\n",
        "  for i in range(3):\n",
        "    print(f[765 + i].split(\"\\t\")[1])\n",
        "    tests.append(f[765 + i].split(\"\\t\")[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A partir de ce moment la, j'arrive plus a contenir mes sentiments mais je sais que la distance fait que rien ne se passera et j'essaye de passer outre, mais j'y arrive pas.\n",
            "\n",
            "A partir de la, c'est la descente aux enfers.\n",
            "\n",
            "A partir de là il est facile de choisir les arguments les plus idiots et de les contredire.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "osvpRl2G0r3-",
        "outputId": "0ac02a17-ed3f-4b4e-c72e-1d179c1c486d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# sents = [sentence_1, sentence_2, sentence_3]\n",
        "\n",
        "ind = 1\n",
        "for sent in tests:\n",
        "\n",
        "  model_best.eval()\n",
        "  src_token = SRC.preprocess(sent)\n",
        "  print(\"src_token:\", src_token)\n",
        "  src_tensor = SRC.process([src_token],device=device)\n",
        "  print(\"shape of source language: \", src_tensor.shape)\n",
        "\n",
        "  trg_token = ['<pad>']*64\n",
        "  trg_tensor = TRG.process([trg_token],device=device)\n",
        "\n",
        "  output, all_attention_weights = model(src_tensor, trg_tensor,teacher_forcing_ratio = 0.0)\n",
        "  output_dim = output.shape[-1] \n",
        "  output_translate = output[1:]\n",
        "\n",
        "  source_language = src_tensor[:,0].cpu().numpy()\n",
        "  translation_logit = output_translate[:,0,:].squeeze(1)\n",
        "  weights = all_attention_weights[0,:,:].squeeze(1).cpu().detach().numpy()\n",
        "\n",
        "  prob, token_id = translation_logit.data.topk(1)\n",
        "  token_id = token_id.squeeze(1).cpu().numpy()\n",
        "\n",
        "  src_language = []\n",
        "\n",
        "  for i in source_language:\n",
        "      if i == SRC.vocab.stoi['<eos>']:\n",
        "          break\n",
        "      else:\n",
        "          token = SRC.vocab.itos[i]\n",
        "          src_language.append(token)\n",
        "  print(\"Source language:\", src_language)\n",
        "\n",
        "  trans_language = []\n",
        "\n",
        "  for i in token_id:\n",
        "      if i == TRG.vocab.stoi['<eos>']:\n",
        "          break\n",
        "      else:\n",
        "          token = TRG.vocab.itos[i]\n",
        "          trans_language.append(token)\n",
        "  print(\"\\n\\tOur model translation: \", trans_language)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src_token: ['a', 'partir', 'de', 'ce', 'moment', 'la', ',', \"j'\", 'arrive', 'plus', 'a', 'contenir', 'mes', 'sentiments', 'mais', 'je', 'sais', 'que', 'la', 'distance', 'fait', 'que', 'rien', 'ne', 'se', 'passera', 'et', \"j'\", 'essaye', 'de', 'passer', 'outre', ',', 'mais', \"j'\", 'y', 'arrive', 'pas', '.']\n",
            "shape of source language:  torch.Size([41, 1])\n",
            "Source language: ['<sos>', 'a', 'partir', 'de', 'ce', 'moment', 'la', ',', \"j'\", 'arrive', 'plus', 'a', 'contenir', 'mes', 'sentiments', 'mais', 'je', 'sais', 'que', 'la', 'distance', 'fait', 'que', 'rien', 'ne', 'se', 'passera', 'et', \"j'\", 'essaye', 'de', 'passer', 'outre', ',', 'mais', \"j'\", 'y', 'arrive', 'pas', '.']\n",
            "\n",
            "\tOur model translation:  ['une', 'presse', 'create', 'create', 'documentary', '3', 'final', 'camembert', 'hairs', 'openly', 'heating', 'avoided', 'earlier', 'bears', 'create', 'internship', 'create', 'meeting', 'none', 'oppose', 'shout', 'gen2', 'telus', 'pretend', 'pretend', 'concepts', 'cg', 'light', 'distinguish', 'programming', 'jerusalem', 'odin', 'electorate', 'handle', 'ended', 'town', 'moving', 'leadership', 'informed', 'informed', 'convicts', 'reaching', 'gave', 'quebeckers', 'quebeckers', 'faure', 'pretend', 'breathing', 'saucepan', 'saucepan', 'metal', 'browser', 'interior', 'testament', 'conditions', 'parking', 'voice', 'products', 'curiosity', 'where', '75', 'products', 'subscribers', 'sad', 'society']\n",
            "src_token: ['a', 'partir', 'de', 'la', ',', \"c'\", 'est', 'la', 'descente', 'aux', 'enfers', '.']\n",
            "shape of source language:  torch.Size([14, 1])\n",
            "Source language: ['<sos>', 'a', 'partir', 'de', 'la', ',', \"c'\", 'est', 'la', 'descente', 'aux', '<unk>', '.']\n",
            "\n",
            "\tOur model translation:  ['physically', 'systems', 'pleasure', 'infrastructure', 'priority', 'rpg', 'lakdim', 'technologies', 'easily', 'csgo', 'observing', 'luxury', 'min', 'linked', 'holes', 'lane', 'incompatible', 'boss', 'flowers', 'context', 'yep', 'iq', 'breton', 'searching', 'goetzmann', 'promising', 'earning', 'shoes', 'shot', 'classic', 'federation', 'marseille', 'regardless', 'iron', 'tradition', 'father', 'ssii', 'lakdim', 'lakdim', 'february', 'delighted', '1200', 'convention', 'raised', 'raised', 'burglar', 'copper', 'buy', 'sweet', 'perfectly', 'supporters', 'médiapart', 'enormous', 'attached', 'iron', 'destroy', 'mais', 'giant', 'therapy', 'trust', 'cheeses', 'cheeses', 'fair', 'fair', 'effects']\n",
            "src_token: ['a', 'partir', 'de', 'là', 'il', 'est', 'facile', 'de', 'choisir', 'les', 'arguments', 'les', 'plus', 'idiots', 'et', 'de', 'les', 'contredire', '.']\n",
            "shape of source language:  torch.Size([21, 1])\n",
            "Source language: ['<sos>', 'a', 'partir', 'de', 'là', 'il', 'est', 'facile', 'de', 'choisir', 'les', 'arguments', 'les', 'plus', 'idiots', 'et', 'de', 'les', '<unk>', '.']\n",
            "\n",
            "\tOur model translation:  ['une', 'health', 'festival', 'meaning', '35', 'associations', 'negotiate', 'bias', 'tests', 'watching', 'construction', 'presenting', 'charline', 'educate', '4', '600', 'neighborhoods', 'toll', 'flow', 'interpretation', 'surface', 'desert', 'letters', 'beef', 'arsenal', 'terminal', 'racket', 'pee', 'move', '05', 'prohibits', 'result', 'proven', 'apart', 'java', 'ways', 'intel', 'teams', 'literature', 'iron', 'tradition', 'father', 'ssii', 'ssii', 'discussing', '33', 'regions', 'cost', 'organizations', 'existence', 'setting', 'built', 'commute', 'assembly', 'luxury', 'flow', 'warn', 'work', 'pastry', 'pen', 'wo', 'crispr', 'attack', 'first', 'faster']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xbfdv08b4OJ0",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}